{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0459851-cca5-49ab-8793-dba1623f5c26",
   "metadata": {},
   "source": [
    "# Preparation of sample dataset with 90 PDF documents in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85ae81f-9fdf-426c-97d1-7ea811f4c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38759b6-075f-4835-b6aa-ec7984f69f4a",
   "metadata": {},
   "source": [
    "### Install `kagglehub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae630460-6207-4f15-9f8f-784ee0c9a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyarrow, kagglehub\n",
    "except: \n",
    "    python = sys.executable\n",
    "    ! {python} -m pip install kagglehub pyarrow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc8a41-da38-40ab-9004-b665df10af78",
   "metadata": {},
   "source": [
    "### Download the whole dataset for exploration\n",
    "\n",
    "To learn more about the dataset, visit [its Kaggle page](https://www.kaggle.com/datasets/manisha717/dataset-of-pdf-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7556836b-9a68-4724-998e-28d43ab47976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path_dataset_kaggle = Path.home() / '.cache/kagglehub/datasets/manisha717'\n",
    "path_folder = path_dataset_kaggle / '/dataset-of-pdf-files/versions/1/Pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d29d0e-3900-4e7c-9808-59a5ae61cd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from Kaggle...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/manisha717/dataset-of-pdf-files?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 769M/769M [00:42<00:00, 18.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "A total of 1078 PDFs have been downloaded to 'C:/Users/carlo/.cache/kagglehub/datasets/manisha717/dataset-of-pdf-files/versions/1/Pdf'\n"
     ]
    }
   ],
   "source": [
    "if not Path(path_dataset_kaggle).exists():\n",
    "    # download latest version\n",
    "    print(\"Downloading dataset from Kaggle...\")\n",
    "    path_dataset_dir = kagglehub.dataset_download(\"manisha717/dataset-of-pdf-files\")\n",
    "    print(\"Done!\")\n",
    "    path_folder = Path(path_dataset_dir) / 'Pdf'\n",
    "    print(f\"A total of {len(os.listdir(path_folder))} PDFs have been downloaded to '{path_folder.as_posix()}'\")\n",
    "else:\n",
    "    print(f\"'{path_folder.as_posix()}' already exists, no need to download it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cbf486-2f82-47cb-b628-f28c37883b19",
   "metadata": {},
   "source": [
    "### Pick only 90 PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a6ecb6-ba3d-44d9-985b-19a33bbcca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_keep = [\n",
    "    'U55XYWRRRDDHAJPPHG6QWKZSAVKMQ5W5',\n",
    "    'R6LHWCGK5EOQHHR7EXRI7ZJLBG2R5QOF',\n",
    "    'GOCYUTJWJZBXHIUSFYG3LVX5SG6HPEVV',\n",
    "    'HXOV2RQJRHU5PDC4PRLJJLU2RT4PSSLV',\n",
    "    'UKNH3OQ2LY6SZKEQ7ITIOEHER4BHZEEN',\n",
    "    'c31721d6245f5689e5d715b1497b2374df7ae4c6',\n",
    "    'ZDFWMKCHQYHS6FUNM6VG6IBZUGFGRP2Z',\n",
    "    '67JSPHIB2F6WUL35OLRAOZ2UEDTI2XZ5',\n",
    "    'ZEVGJOLU5PKURGKDQ3GMLEWFTBUGJXT6',\n",
    "    '37WOUPCWLZGR4AFDBNNHKUHNTVLYXVLD',\n",
    "    'CI7INUGNXV4CY2ETA4PM5IOKZNUM5A2T',\n",
    "    'UFTWPHWPAMA7G4B6F5SMUFNA3HU6H5UW',\n",
    "    'I74UK7CA3VD36AJLDMBKXZHMRBRV6KNF',\n",
    "    'X5LYOK62EFBFVPNGADYEJUVEZJTZDHMC',\n",
    "    'SZYITDQYKPK6FN4ZP4NZB5QTKLZFT326',\n",
    "    '887c6fd22c2be24a023105b3fb23d5e29dfd8055',\n",
    "    'SXHJPFKQMVB3WUA6WOCOATLLVMBWKCCS',\n",
    "    'QU4F5C3GPRUAV463D7PN5NXHKFCWJETA',\n",
    "    'DR44GMFR57CROQCOUET6BVBGBYZW5HJ5',\n",
    "    'EB46IVVKTIHXKYY42XWKUM64HY2USGTZ',\n",
    "    'FC2VGRC55DZ77QA4O5L7DPBQEUDIQG52',\n",
    "    'WCILDJ3BDTTDKHJ3HGRQD2SF45E55AXN',\n",
    "    'O4Z3IEED7ROYYCKDRARK2BBHSZGR4M5Y',\n",
    "    'P7ZED35W7LHI6YLKM5TVSLOQVACYSHHM',\n",
    "    'YV3RJXNXP6ZR6V2SSVVQJWYAHBZSZ3GQ',\n",
    "    '2XJLJAFHRTLAIWFDDAVMV2U4QJMISM4P',\n",
    "    '65UHUSAELNKVXUYGUXKY2JQLAKWINVC2',\n",
    "    'J4XIQKGR5I6GKS2RD2IWEWCUNLVEFSZO',\n",
    "    'CMLZOTTP4BCWEEGZ2OATUKNBQGGIZ4OA',\n",
    "    'HCPCI34AEBKDUFDP442OTOL2AUGIG3BJ',\n",
    "    'TYLWGSX5OYKE27DHTQXUJTBMKMHMKY3B',\n",
    "    'S2M644RTRLI4BC6XSMMWE2MRFB76F4KC',\n",
    "    'QDT4ROBASSEPQJ22EDUO3HLP3NB2IIBC',\n",
    "    'TBI3APZQ4LEU3AO3OLYNCZLYYOO4ZOLB',\n",
    "    'HB2IHQ5EY4MV6YIJNCKSZ5L2EA6BPV75',\n",
    "    'R7RUWIVERCT2LRQCIKTTVL3SXF4P4HEP',\n",
    "    'OHTNKYOXYDGU2LJ65NZHLLFUCLSNEGNU',\n",
    "    'JTJQSY6SJUAI2P54IHQQYCVFMCWPXVTN',\n",
    "    '2FDPTMT2NZDE6RIJSZZXGBMD7LYL7YHV',\n",
    "    'SSC5AFOSRRYRFIB7FNROD3UUH2WQL5DV',\n",
    "    '7GYQLFBVGRTYWE73NKCNCODTJVURFULB',\n",
    "    'Z3WZ7DRI3LWQUHWWRHOMKHBF3A5L4NTD',\n",
    "    '3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB',\n",
    "    'TQSAKC5ZXKO27EPBJ7HLTN2K3CW5L4MR',\n",
    "    'X5J2UFQ52GKUF4JQCQ4DPJ62QF2EJ2XG',\n",
    "    '6F47YISD72RZCG6OYZQCQLCYJX5E7MBK',\n",
    "    '3P5D3UKXU2R6I2TK4OJSLL6LGIQJ4NY5',\n",
    "    'EIR7WZL6LLXE7N7TX5ZY4QKXPPZEISPQ',\n",
    "    'RZBL4G73Y76GIJWY3BENQNYBTVX5WAR6',\n",
    "    '44fd6224a81709051890169e2533ac5fd75cd93a',\n",
    "    'OB5K37VVGHIEXSQPWFJBU7NZA5OEKAOO',\n",
    "    '2LVOKCURIEQKLK43I6T7QLYYQX3RQUXX',\n",
    "    'B5PCEYSOV53475ZZQE7OPLN4FUVDRC7Y',\n",
    "    'JXM2RAH5DJSVW2XCEGXVMU2PFPC4J3P4',\n",
    "    '2UD7BSKC7GT3V7I6DK5NH5TFKJ6F3EXL',\n",
    "    '281928eff64137efdd144a833c81ad0ee45284c1',\n",
    "    'DJB3ZGUGJANSX3J2RPJJU6L4OPGKC2NK',\n",
    "    '7IYBO6EFOFMF4ETCCIZYJEGPTBQY3EE5',\n",
    "    'D3BLEFGEYIMPXCDAJJUYBTSMJEAURKTV',\n",
    "    'L3YHCAZRLQVYA7O4G6SG5BQHUREJTYQO',\n",
    "    'P27OC5LB5CYK7PNMUUFAMXEQ3THDTNJ4',\n",
    "    'X2T7N7IH7E45XFYXNJH5Q3AYJU4BEC57',\n",
    "    'HVP5WMRFWBOCTMMV6NC57S2QJ674CGXG',\n",
    "    'M6C6DEQ5LEULRCOK2LEADJ3AX3522H3E',\n",
    "    '76P47DRTKG4I3M56ZPDSWTVW4AC37RWI',\n",
    "    'SW6G4QILYS7QYXXVHMGTCXFHYU2QHV6Z',\n",
    "    'ON2LIHQQ5QFF6JIQGMUDF7ALYUDKTTV6',\n",
    "    '4VXCOS4VUT37JP4BK425KOKWXRYTMJDO',\n",
    "    'RVF6AZOJLCDEWLY2UNGVFQ4PSVEQYAUH',\n",
    "    'DGZ2C5RQO4EDW2XQHLWDCCJZUB6IQLCE',\n",
    "    'OEJKXSDUJIM5XWYEYLA2NWL3K4UI5IZR',\n",
    "    'JGLEJ4HUZGQBXUZ3ZXUWHSPYIDVKVU2K',\n",
    "    'OQCH5BPQO3G64HZOGOJKA26NQ23FAXD2',\n",
    "    'AOZ2LBQOYCC5F3KFBN3FUGN2FODM6DCU',\n",
    "    'AMTYOKGXFE7QNNQKJ73HZRLDKD3CSQW2',\n",
    "    'KMELIR3DJDUFB52NSPC42LSIU6OOD77U',\n",
    "    'KWL6TCYCODD5ODQXOPLOAX46TIM557CL',\n",
    "    'XTYOD5JGKSMJAATU6RT4WK3LPOYBGYJY',\n",
    "    'QZTQ7BCZVBR4UKL4M73HH7TX4ZVROQCS',\n",
    "    'YCYN7CHWTHPZYST4LVE2OHZC2Y4INSNZ',\n",
    "    'TEEGK5AIZ426F27JXF2QAPKENCTIT2GG',\n",
    "    'GLXEDNT3LDSIPA6BGJGFIUEXOBO4NRDE',\n",
    "    'JYMSHAQOPOCHYVWZYLPSNQYDNAGMT5DR',\n",
    "    'QSPE3BHAI3DOO552RNZ5WXPJVIWAZ4LT',\n",
    "    'KAX2V43VIPOF5R7SL2YYD2JQFRQCPWQ5',\n",
    "    '7ODKVGAYKZTRQVTJRVNSXSEK3QC43I3B',\n",
    "    'POKED5F2QVX266ONHVMGK7AGDJDU7OYQ',\n",
    "    'HLGUA2TVCFAMJQDFC5IC43JBVUOFXDWB',\n",
    "    'ILRVVACIV2JDSO4LHLATCOCKSEQYZCMZ',\n",
    "    'WPSL4I6DPEKQWLMHVD5TRXPBVMN3MUFW'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6aeed2d-6edc-4806-84fc-0314ec35c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in folder: 1078\n",
      "Keeping only 90 files\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(path_folder)\n",
    "print(f\"Number of documents in folder: {len(files)}\")\n",
    "\n",
    "files_to_keep = [file for file in files \n",
    "                 if file.replace('.pdf', '') in ids_to_keep]\n",
    "\n",
    "print(f\"Keeping only {len(files_to_keep)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c7cc5c3-11d0-4a90-9907-40094d73f848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['281928eff64137efdd144a833c81ad0ee45284c1.pdf',\n",
       " '2FDPTMT2NZDE6RIJSZZXGBMD7LYL7YHV.pdf',\n",
       " '2LVOKCURIEQKLK43I6T7QLYYQX3RQUXX.pdf',\n",
       " '2UD7BSKC7GT3V7I6DK5NH5TFKJ6F3EXL.pdf',\n",
       " '2XJLJAFHRTLAIWFDDAVMV2U4QJMISM4P.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_keep[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ad744e-20b2-485d-a28e-2f8e7030c441",
   "metadata": {},
   "source": [
    "> ### ðŸ“ **Note**:\n",
    "> \n",
    "> If you want to create your own sample dataset with different documents, you can run this:\n",
    "> ```python\n",
    ">    import random\n",
    ">    \n",
    ">    n_docs = 100\n",
    ">    # 'path_pdfs' is returned by method \"kagglehub.dataset_download\"\n",
    ">    path_folder = Path(path_pdfs) / 'Pdf'\n",
    ">    \n",
    ">    files = os.listdir(path_folder)\n",
    ">    print(f\"Number of documents in folder: {len(files)}\")\n",
    ">    print(f\"Keeping only {n_docs} files\")\n",
    ">    \n",
    ">    random.seed(42)  # for reproducibility of the files to keep\n",
    ">    random.shuffle(files)\n",
    ">    files_to_keep = files[:n_docs]\n",
    ">    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b12f1-9808-44dc-a639-9f0c3156ca31",
   "metadata": {},
   "source": [
    "### Store the picked PDFs in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9170d0aa-23f3-4335-bfb6-e9a09ad60291",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for filename in files_to_keep:\n",
    "    time_insert = pd.Timestamp.now().to_numpy()  # mimicking \"insertion time\"\n",
    "    path_pdf = path_folder / filename\n",
    "    doc_id = Path(path_pdf).name.replace(\".pdf\", \"\")\n",
    "    \n",
    "    with open(path_pdf, 'rb') as pdf:\n",
    "        pdf_bytes = pdf.read()\n",
    "        records.append({\n",
    "            'time_insert':         time_insert,\n",
    "            'document_identifier': doc_id,\n",
    "            'content':             pdf_bytes,\n",
    "        })\n",
    "\n",
    "df_pdf_docs = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1331a1cf-90e6-4e80-89cc-287929d82182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdf_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bbd9a9c-e4c3-471f-ae89-6f471e1a0122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_insert</th>\n",
       "      <th>document_identifier</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-04 15:46:34.392272</td>\n",
       "      <td>281928eff64137efdd144a833c81ad0ee45284c1</td>\n",
       "      <td>b'%PDF-1.7\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n146 0 obj\\r&lt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-04 15:46:34.421531</td>\n",
       "      <td>2FDPTMT2NZDE6RIJSZZXGBMD7LYL7YHV</td>\n",
       "      <td>b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n27 0 obj\\r&lt;&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-04 15:46:34.448864</td>\n",
       "      <td>2LVOKCURIEQKLK43I6T7QLYYQX3RQUXX</td>\n",
       "      <td>b'%PDF-1.4\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n468 0 obj\\r&lt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-04 15:46:34.469973</td>\n",
       "      <td>2UD7BSKC7GT3V7I6DK5NH5TFKJ6F3EXL</td>\n",
       "      <td>b'%PDF-1.5\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n1869 0 obj\\r&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-04 15:46:34.486475</td>\n",
       "      <td>2XJLJAFHRTLAIWFDDAVMV2U4QJMISM4P</td>\n",
       "      <td>b'%PDF-1.4\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n303 0 obj\\r&lt;&lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time_insert                       document_identifier  \\\n",
       "0 2025-05-04 15:46:34.392272  281928eff64137efdd144a833c81ad0ee45284c1   \n",
       "1 2025-05-04 15:46:34.421531          2FDPTMT2NZDE6RIJSZZXGBMD7LYL7YHV   \n",
       "2 2025-05-04 15:46:34.448864          2LVOKCURIEQKLK43I6T7QLYYQX3RQUXX   \n",
       "3 2025-05-04 15:46:34.469973          2UD7BSKC7GT3V7I6DK5NH5TFKJ6F3EXL   \n",
       "4 2025-05-04 15:46:34.486475          2XJLJAFHRTLAIWFDDAVMV2U4QJMISM4P   \n",
       "\n",
       "                                             content  \n",
       "0  b'%PDF-1.7\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n146 0 obj\\r<<...  \n",
       "1  b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n27 0 obj\\r<</...  \n",
       "2  b'%PDF-1.4\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n468 0 obj\\r<<...  \n",
       "3  b'%PDF-1.5\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n1869 0 obj\\r<...  \n",
       "4  b'%PDF-1.4\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n303 0 obj\\r<<...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdf_docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034b26f-f039-49b2-9163-a8e0f8489138",
   "metadata": {},
   "source": [
    "### Write dataframe to parquet in a Spark-version-safe manner\n",
    "\n",
    "Depending on your configuration, Spark may raise an error when you attempt to read with **Spark** a parquet file that was created with **Pandas** and that contains timestamp columns. When you do run `spark.read.parquet()`, Spark may respond with: `org.apache.spark.sql.AnalysisException: Illegal Parquet type: INT64 (TIMESTAMP(NANOS,false))`. This is caused by an incompatibility, when it comes to compressing timestamp data, between the engine Pandas uses to create the Parquet file, and the one Spark uses to read the file. If you encounter that error, you can fix it by creating the parquet with Pandas with a **timestamp format compatible with the one Spark expects**:\n",
    "\n",
    "```python\n",
    "pdf_docs.to_parquet('your_data.parquet', allow_truncated_timestamps=True, coerce_timestamps='ms')\n",
    "```\n",
    "\n",
    "To learn more, visit [this StackOverflow post](https://stackoverflow.com/questions/57699926/how-to-fix-illegal-parquet-type-int64-timestamp-micros-error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba77bda3-992d-42b0-85be-027fe8873e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_data_folder():\n",
    "    NAME_REPO = 'articles'\n",
    "    home_repo = [parent for parent in Path.cwd().parents if parent.name == NAME_REPO][0]\n",
    "    folder_data = home_repo / 'data'\n",
    "    return folder_data\n",
    "\n",
    "folder_data = get_path_data_folder()\n",
    "\n",
    "folder_data.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c02b769c-6b06-4f8d-9717-a171cc7d580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet file saved at: 'C:/Users/carlo/Projects/articles/data/table_90_pdf_documents.parquet'\n"
     ]
    }
   ],
   "source": [
    "n_docs = df_pdf_docs.shape[0]\n",
    "parquet_name = folder_data / f'table_{n_docs}_pdf_documents.parquet'\n",
    "\n",
    "df_pdf_docs.to_parquet(parquet_name, \n",
    "                       allow_truncated_timestamps=True, \n",
    "                       coerce_timestamps='ms')  # to prevent Spark compatibility issues\n",
    "print(f\"Parquet file saved at: '{parquet_name.as_posix()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b63150e-a982-41d3-a071-6057809e0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert parquet_name.exists(), \"File wasn't saved properly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f4d51-443a-4d21-bbb2-87e7619a9848",
   "metadata": {},
   "source": [
    "### Optional: Deleting the original dataset\n",
    "\n",
    "You have saved a sample dataset. If you don't plan to use the full dataset, and want to save some space (it weighs 769 MB), you can delete the folder you downloaded with `kagglehub` by doing: \n",
    "\n",
    "```python\n",
    "import shutil\n",
    "\n",
    "if path_dataset_kaggle.exists():\n",
    "    print(f\"Deleting folder '{path_dataset_kaggle}' and all its contents ....\")\n",
    "    shutil.rmtree(path_dataset_kaggle)\n",
    "    print(\"Done.\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
